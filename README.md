1. Revising Python
- revised python through a short crash course by mosh hamedani, made notes in notebook


2. Learning Numpy and Pandas
- practiced and learnt more about numpy and pandas libraries in python, both of which are very essential for ML
- numpy = https://github.com/KeithGalli/NumPy, pandas = https://github.com/KeithGalli/pandas (notes were already there, i just imported them in jupyter on my pc)


3. Starting with Neural networks (mostly theorotical) = https://www.youtube.com/watch?v=Gv9_4yMHFhI&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF
- Learnt about backpropogation, weights, biases, linear regression, gradient descent, loss function
- predicting a squiggle/graph to fit the observed values through a neural network
- learnt about neural networks with multiple inputs and outputs, argmax, softmax, cross entropy etc
- learnt advanced neural networks through RNNs, LSTMs, Word2Vec
- learnt about encoders, decoders, transformer neural networks and ultimately the basic decoder type transformer neural networks of LLMs like chatgpt


4. Starting with Pytorch
- learnt about tensor operations and matrices, pytorch nn modules, model optimizers etc


5. The Final Project - https://www.youtube.com/watch?v=kCc8FmEb1nY&list=PPSV
Objective : trying to make a decoder only transformer based LLM that can be trained using large set of data files
Procedure : feeding in text files with human conversations / shakespeare writings and training our LLM to generate an output similar to the given input with the highest trainable accuracy possible

